{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1**. (100 points)\n",
    "\n",
    "In this exercise you will use Spark to build and run a machine learning pipeline to separate 'ham' from 'spam' in SMS text messages. Then you will use the pipeline to classify SMS texts.\n",
    "\n",
    "- Create a Pandas DataFraem form the data in the file`SMSSpamCollection` where each line is tab separated into (label, text). If you find that the read_xxx function in Pandas does not do the job correctly, read in the file line by line before converting to a DataFrame. Create an index column so that each row has a unique number id.\n",
    "- Convert to a Spark DataFrame that has two columns (klass, SMS) and split into test and training data sets with proportions 0.8 and 0.2 respectively using a random seed of 123.\n",
    "- Build a Spark ML pipeline consisting of the following \n",
    "    - StringIndexer: To convert `klass` into a numeric `labels` column\n",
    "    - Tokenizer: To covert `SMS` into a list of tokens\n",
    "    - StopWordsRemover: To remove \"stop words\" from the tokens\n",
    "    - CountVectorizer: To count words (use a vocabular size of 100 and minimum number of occureences of 2)\n",
    "    - LogisticRegression: Use `maxIter=10`, `regParam=0.001`\n",
    "\n",
    "- Train the model on the test data.\n",
    "- Evaluate the precision, recall and accuracy of this model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2** (100 points)\n",
    "\n",
    "In this exercise, you will simulate running a machine learning pipeline to classify steaming data.\n",
    "\n",
    "- Convert the test DataFrame into a Pandas DataFrame\n",
    "- Write each row of the DataFrame to a separate tab-delimited file in a folder called \"incoming_sms\"\n",
    "- Create a Structured Streaming DataFrame using `readStream` with `option(\"maxFilesPerTrigger\", 1)` to simulate streaming data\n",
    "- Use the fitted pipeline created in Ex. 1 to transform the input stream\n",
    "- Write the transformed stream to memory with name `sms_pred\n",
    "- Sleep 30 seconds\n",
    "- Use an SQL query to show the `index`, `label` and `prediction` columns\n",
    "- Sleep 30 more seconds\n",
    "- Use an SQL query to show the `index`, `label` and `prediction` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
